<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <title>ControLRM: Fast and Controllable 3D Generation via Large Reconstruction Model</title>
	<!-- <link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico"> -->
    <link rel="icon" type="image/x-icon" href="assets/images/paintbrush.ico">
    <meta content="ControLRM: Fast and Controllable 3D Generation via Large Reconstruction Model" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
</head>

<body>
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            
            <!-- <h1 class="nerf_title_v2">SweetDreamer: Aligning Geometric Priors <br> in 2D Diffusion for Consistent Text-to-3D</h1> -->
            <h1 class="nerf_title_v2">ControLRM: Fast and Controllable 3D Generation via Large Reconstruction Model</h1>
            <!-- <div class="nerf_subheader_v2">ICLR 2024</div> -->
            <div class="nerf_subheader_v2">
                <div>
                    <a href="https://scholar.google.com/citations?user=mRC_emoAAAAJ" target="_blank" class="nerf_authors_v2">Hongbin Xu<span
                        class="text-span_nerf"></span></a><sup>1,2</sup>,&nbsp;&nbsp;
                    <a href="" target="_blank" class="nerf_authors_v2">Weitao Chen<span
                        class="text-span_nerf"></span></a><sup>3</sup>,&nbsp;&nbsp;
                    <a href="" target="_blank" class="nerf_authors_v2">Zhipeng Zhou<span
                        class="text-span_nerf"></span></a><sup>4</sup>,&nbsp;&nbsp;
                    <a href="" target="_blank" class="nerf_authors_v2">Feng Xiao<span
                        class="text-span_nerf"></span></a><sup>3</sup>,&nbsp;&nbsp;
                    <a href="" target="_blank" class="nerf_authors_v2">Baigui Sun<span
                        class="text-span_nerf"></span></a><sup>3</sup>,&nbsp;&nbsp;    
                    <a href="https://sites.google.com/view/showlab" target="_blank" class="nerf_authors_v2">Mike Zheng Shou<span
                        class="text-span_nerf"></span></a><sup>2</sup>,&nbsp;&nbsp; 
                    <a href="" target="_blank" class="nerf_authors_v2">Wenxiong Kang<span
                        class="text-span_nerf"></span></a><sup>1</sup>,&nbsp;&nbsp;   
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>1 </sup>South China University of Technology</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>2 </sup>National University of Singapore</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>3 </sup>Alibaba Group</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>4 </sup>University of Chinese Academy of Sciences</h1>
                </div>

                <div class="external-link">
                    <a class="btn" href="http://arxiv.org/abs/2310.02596" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn" href="paper/paper.pdf" role="button" target="_blank">
                        <i class="fa fa-file-pdf"></i> Paper </a>
                    <a class="btn" href="" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code </a>
                    <a class="btn btn-large btn-light" href="" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-youtube"></i> Video </a>
                </div>

            </div>
        </div>

    </div>


    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                Despite recent advancements in 3D generation methods, achieving controllability still 
                remains a challenging issue. Current approaches utilizing score-distillation sampling 
                are hindered by laborious procedures that consume a significant amount of time. 
                Furthermore, the process of first generating 2D representations and then mapping them 
                to 3D lacks internal alignment between the two forms of representation. To address 
                these challenges, we introduce ControLRM, an end-to-end feed-forward model designed for
                rapid and controllable 3D generation using a large reconstruction model (LRM). ControLRM 
                comprises a 2D condition generator, a condition encoding transformer, and a triplane 
                decoder transformer. Instead of training our model from scratch, we advocate for a joint
                training framework. In the condition training branch, we lock the triplane decoder and 
                reuses the deep and robust encoding layers pretrained with millions of 3D data in LRM. 
                In the image training branch, we unlock the triplane decoder to establish an implicit
                alignment between the 2D and 3D representations. To ensure unbiased evaluation, we 
                curate evaluation samples from three distinct datasets (G-OBJ, GSO, ABO) rather than 
                relying on cherry-picking manual generation. The comprehensive experiments conducted on
                quantitative and qualitative comparisons of 3D controllability and generation quality 
                demonstrate the strong generalization capacity of our proposed approach.

                <!-- Lifting 2D observations in pre-trained diffusion models to a 3D world for text-to-3D 
		is inherently ambiguous. 2D diffusion models solely learn view-agnostic
                priors and thus lack 3D knowledge during the lifting, leading to the multi-view
                inconsistency problem. Our key finding reveals that this problem primarily stems
                from geometric inconsistency, and addressing ambiguously placed geometries
                substantially mitigates the issue in the final outcomes. Therefore, we focus on
                improving the geometric consistency via enforcing the 2D geometric priors in diffusion 
		models act in a way that aligns with well-defined 3D geometries during the
                lifting, addressing the vast majority of the problem. This is realized by fine-tuning
                the 2D diffusion to be viewpoint-aware and to produce view-specific geometric
                maps of canonically oriented objects as in 3D datasets. Particularly, only coarse
                3D geometries are used for aligning. This “coarse” alignment not only enables
                the generation of geometries without multi-view inconsistency but also retains the
                ability in 2D diffusion models to generate high-quality geometries of arbitrary objects 
		unseen in 3D datasets. Furthermore, our <b style="color: rgb(124, 196, 245);">Aligned Geometric Priors (AGP)</b> are
                generic and can be seamlessly integrated into various state-of-the-art pipelines,
                obtaining high generalizability in terms of unseen geometric structures and visual
                appearance while greatly alleviating multi-view inconsistency issues, and hence
                representing a new state-of-the-art performance in text-to-3D. -->
                <br>
                <!-- <img  src="assets/images/overview.png"> -->
            </p>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Performance Overview</h2>
        <div class="grid-container-1">
            <img src="assets/images/comparison_introduction.png">

            <p>
                Performance and efficiency comparison among different conditional 3D generation methods. 
                Fig. (a) shows the average time consumption on a single V100-32G GPU of different methods. 
                Our ControLRM-T and ControLRM-D can respectively achieve 60 and 18 times faster inference
                speed compared with the fastest baseline, MVControl [14]. Fig (b) shows the results of 15 
                evaluation metrics on the G-Objaverse test set, including 3D controllability metrics (introduced 
                in Sec. 4.2.1 of the paper) and controllable 3D generation metrics (introduced in Sec. 4.3.1 of the paper).
            </p>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Method Overview</h2>
        <div class="grid-container-1">
            <img src="assets/images/method.jpg">

            <p>
                The overall framework of ControLRM, a feed-forward controllable 3D generation model. ControLRM comprises a 2D condition generator, a
                condition encoding transformer, and a triplane decoder transformer. Instead of training our model from scratch, we advocate for a joint
                training framework. In the condition training branch, we lock the triplane decoder and reuses the deep and robust encoding layers
                pretrained with millions of 3D data in LRM. In the image training branch, we unlock the triplane decoder to establish an implicit
                alignment between the 2D and 3D representations.
            </p>
        </div>
    </div>


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Generated Results with Edge(Canny) Condition </h2>
        <p>
            Generated results given <b>Edge (Canny)</b> condition. The first row shows the input condition, the second row shows the results
            of our <b>ControLRM-D</b>, and the third row shows the results of <b>MVControl</b>. You can change the visualization mode between 
            rendered RGB images and depth maps via <b>dragging the sliders</b>.
        </p>
        <div class="grid-container-6">
            <div>
                <p class="myprompt nerf_text"><i>A purple teapot with a small horned hat.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_canny_000011.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A red and white plastic cup with a straw.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_canny_000012.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>Thor Hammer.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_canny_000017.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A cartoon rocket ship with a person riding in it, flying in the air.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_canny_000019.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>Purple sniper rifle.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_canny_000020.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A wooden crate with a cross design on it.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_canny_000053.png" width="256" height="256">
            </div>
        </div>

        <div class="grid-container-6">
            <div>
                <video class="video" id="E1" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_canny_000011.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="E1_merge"></canvas>
            </div>
            <div>
                <video class="video" id="E2" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_canny_000012.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="E2_merge"></canvas>
            </div>
            <div>
                <video class="video" id="E3" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_canny_000017.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="E3_merge"></canvas>
            </div>
            <div>
                <video class="video" id="E4" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_canny_000019.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="E4_merge"></canvas>
            </div>
            <div>
                <video class="video" id="E5" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_canny_000020.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="E5_merge"></canvas>
            </div>
            <div>
                <video class="video" id="E6" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_canny_000053.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="E6_merge"></canvas>
            </div>
        </div>

        <div class="grid-container-6">
            <div>
                <video class="video" id="E1" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_canny_000011.mp4"></video>
            </div>
            <div>
                <video class="video" id="E2" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_canny_000012.mp4"></video>
            </div>
            <div>
                <video class="video" id="E3" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_canny_000017.mp4"></video>
            </div>
            <div>
                <video class="video" id="E4" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_canny_000019.mp4"></video>
            </div>
            <div>
                <video class="video" id="E5" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_canny_000020.mp4"></video>
            </div>
            <div>
                <video class="video" id="E6" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_canny_000053.mp4"></video>
            </div>
        </div>

    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Generated Results with Sketch Condition </h2>
        <p>
            Generated results given <b>Sketch</b> condition. The first row shows the input condition, the second row shows the results
            of our <b>ControLRM-D</b>, and the third row shows the results of <b>MVControl</b>. You can change the visualization mode between 
            rendered RGB images and depth maps via <b>dragging the sliders</b>.
        </p>
        <div class="grid-container-6">
            <div>
                <p class="myprompt nerf_text"><i>Wooden Barrel Model.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_sketch_000061.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>Low poly a hamburger.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_sketch_000086.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>An axe.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_sketch_000088.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A wooden console side table with drawers and shelves, featuring holes for added detail..</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_sketch_000189.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A sword with a blue handle.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_sketch_000199.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A small wooden house with a tin roof.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_sketch_000319.png" width="256" height="256">
            </div>
        </div>

        <div class="grid-container-6">
            <div>
                <video class="video" id="S1" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_sketch_000061.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="S1_merge"></canvas>
            </div>
            <div>
                <video class="video" id="S2" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_sketch_000086.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="S2_merge"></canvas>
            </div>
            <div>
                <video class="video" id="S3" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_sketch_000088.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="S3_merge"></canvas>
            </div>
            <div>
                <video class="video" id="S4" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_sketch_000189.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="S4_merge"></canvas>
            </div>
            <div>
                <video class="video" id="S5" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_sketch_000199.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="S5_merge"></canvas>
            </div>
            <div>
                <video class="video" id="S6" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_sketch_000319.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="S6_merge"></canvas>
            </div>
        </div>

        <div class="grid-container-6">
            <div>
                <video class="video" id="1" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_sketch_000061.mp4"></video>
            </div>
            <div>
                <video class="video" id="2" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_sketch_000086.mp4"></video>
            </div>
            <div>
                <video class="video" id="3" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_sketch_000088.mp4"></video>
            </div>
            <div>
                <video class="video" id="4" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_sketch_000189.mp4"></video>
            </div>
            <div>
                <video class="video" id="5" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_sketch_000199.mp4"></video>
            </div>
            <div>
                <video class="video" id="6" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_sketch_000319.mp4"></video>
            </div>
        </div>

    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Generated Results with Depth Condition </h2>
        <p>
            Generated results given <b>Depth</b> condition. The first row shows the input condition, the second row shows the results
            of our <b>ControLRM-D</b>, and the third row shows the results of <b>MVControl</b>. You can change the visualization mode between 
            rendered RGB images and depth maps via <b>dragging the sliders</b>.
        </p>
        <div class="grid-container-6">
            <div>
                <p class="myprompt nerf_text"><i>A red apple.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_depth_000075.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A fur-covered, camouflage-patterned, wooden chair with brown and tan accents.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_depth_000186.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>Minecraft hammer model with a white pole.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_depth_000308.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A purple chair with holes and a back, featuring a plastic seat and legs.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_depth_000324.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A small garage or bus stop with a red roof.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_depth_000328.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A steampunk gun model with a scope, featuring a wooden handle, gold accents, and a metal barrel.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_depth_000348.png" width="256" height="256">
            </div>
        </div>

        <div class="grid-container-6">
            <div>
                <video class="video" id="D1" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_depth_000075.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="D1_merge"></canvas>
            </div>
            <div>
                <video class="video" id="D2" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_depth_000186.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="D2_merge"></canvas>
            </div>
            <div>
                <video class="video" id="D3" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_depth_000308.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="D3_merge"></canvas>
            </div>
            <div>
                <video class="video" id="D4" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_depth_000324.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="D4_merge"></canvas>
            </div>
            <div>
                <video class="video" id="D5" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_depth_000328.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="D5_merge"></canvas>
            </div>
            <div>
                <video class="video" id="D6" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_depth_000348.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="D6_merge"></canvas>
            </div>
        </div>

        <div class="grid-container-6">
            <div>
                <video class="video" id="1" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_depth_000075.mp4"></video>
            </div>
            <div>
                <video class="video" id="2" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_depth_000186.mp4"></video>
            </div>
            <div>
                <video class="video" id="3" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_depth_000308.mp4"></video>
            </div>
            <div>
                <video class="video" id="4" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_depth_000324.mp4"></video>
            </div>
            <div>
                <video class="video" id="5" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_depth_000328.mp4"></video>
            </div>
            <div>
                <video class="video" id="6" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_depth_000348.mp4"></video>
            </div>
        </div>

    </div>


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Generated Results with Normal Condition </h2>
        <p>
            Generated results given <b>Normal</b> condition. The first row shows the input condition, the second row shows the results
            of our <b>ControLRM-D</b>, and the third row shows the results of <b>MVControl</b>. You can change the visualization mode between 
            rendered RGB images and depth maps via <b>dragging the sliders</b>.
        </p>
        <div class="grid-container-6">
            <div>
                <p class="myprompt nerf_text"><i>An axe.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_normal_000382.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A green military crate with a metal handle.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_normal_000435.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>White toilet model.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_normal_000463.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A vintage wooden radio with an attached cord.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_normal_000506.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A white woven bag with wooden handles.</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_normal_000522.png" width="256" height="256">
            </div>
            <div>
                <p class="myprompt nerf_text"><i>A LEGO gun with a purple light, resembling a small robotic device..</i> <br>&nbsp</p>
                <img src="assets/videos/ours/gobj_condition_normal_000534.png" width="256" height="256">
            </div>
        </div>

        <div class="grid-container-6">
            <div>
                <video class="video" id="N1" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_normal_000382.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="N1_merge"></canvas>
            </div>
            <div>
                <video class="video" id="N2" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_normal_000435.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="N2_merge"></canvas>
            </div>
            <div>
                <video class="video" id="N3" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_normal_000463.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="N3_merge"></canvas>
            </div>
            <div>
                <video class="video" id="N4" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_normal_000506.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="N4_merge"></canvas>
            </div>
            <div>
                <video class="video" id="N5" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_normal_000522.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="N5_merge"></canvas>
            </div>
            <div>
                <video class="video" id="N6" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_controlrmd_normal_000534.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="N6_merge"></canvas>
            </div>
        </div>

        <div class="grid-container-6">
            <div>
                <video class="video" id="1" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_normal_000382.mp4"></video>
            </div>
            <div>
                <video class="video" id="2" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_normal_000435.mp4"></video>
            </div>
            <div>
                <video class="video" id="3" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_normal_000463.mp4"></video>
            </div>
            <div>
                <video class="video" id="4" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_normal_000506.mp4"></video>
            </div>
            <div>
                <video class="video" id="5" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_normal_000522.mp4"></video>
            </div>
            <div>
                <video class="video" id="6" loop playsinline autoPlay muted
                src="assets/videos/ours/gobj_mvcontrol_normal_000534.mp4"></video>
            </div>
        </div>

    </div>

    


    <!-- <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">NeRF-based Generated Results</h2>
        <div class="grid-container-4">
            <div>
                <p class="myprompt nerf_text">A dragon-cat hybrid <br>&nbsp</p>
                <video class="video" id="1" loop playsinline autoPlay muted
                src="assets/videos/nerf-based/exp_30.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="1_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">Albert Einstein with grey suit is riding a bicycle</p>
                <video class="video" id="3" loop playsinline autoPlay muted
                src="assets/videos/nerf-based/Einstein.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="3_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">Mini Paris, highly detailed, <br>8K, HD</p>
                <video class="video" id="2" loop playsinline autoPlay muted
                src="assets/videos/nerf-based/miniParis.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="2_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A 3D model of mini China town, highly detailed, 8K, HD, blender 3d</p>
                <video class="video" id="0" loop playsinline autoPlay muted
                src="assets/videos/nerf-based/ChinaTown.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="0_merge"></canvas>
            </div>
        </div>
        <div class="grid-container-1">
            <a class="mybtn" href="nerf-based-gallery_0.html" role="button">
             More Results </a>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">DMTet-based Generated Results</h2>
        <div class="grid-container-4">
            <div>
                <p class="myprompt nerf_text">A boy in mohawk hairstyle, head only, 4K, HD, raw</p>
                <video class="video" id="10" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/2023_10_08/aboyinmohawkhairstyle_appearance.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="10_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">Fire-breathing Phoenix, mythical bird, engulfed in flames, <br>rebirth and renewal, 3D render, 8K, HD</p>
                <video class="video" id="11" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/Phoenix7_appearance3.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="11_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A bulldog wearing a black pirate hat, highly detailed</p>
                <video class="video" id="12" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/dog_appearance8.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="12_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A 3D model of mini China town, highly detailed, 8K, HD, blender 3d</p>
                <video class="video" id="13" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/2023_10_05/ChinaTown0_appearance.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="13_merge"></canvas>
            </div>
        </div>

        <div class="grid-container-1">
            <a class="mybtn" href="dmtet-based-gallery_0.html" role="button">
            More Results </a>
        </div>
    </div> -->


    <!-- <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Method Overview</h2>
        <div class="grid-container-1">
            <img src="assets/images/overview_pipelines.png">

            <p>We fine-tune the 2D diffusion model (middle) to generate viewpoint-
    conditioned canonical coordinates maps, which are rendered from canonically oriented 3D assets
    (left), thereby aligning the geometric priors in the 2D diffusion. The aligned geometric priors can
    then be seamlessly integrated into existing text-to-3D pipelines to confer 3D consistency (right),
    while retaining their generalizability to obtain high-fidelity and highly varied 3D content.
            </p>
        </div>
    </div> -->

    <!-- <div class="white_section_nerf grey_container w-container">
    <h2 class="grey-heading_nerf">BibTeX</h2>
    <div class="bibtex">
        <pre><code>@article{sweetdreamer,
    author    = {Weiyu Li and Rui Chen and Xuelin Chen and Ping Tan},
    title     = {SweetDreamer: Aligning Geometric Priors in 2D Diffusion for Consistent Text-to-3D},
    journal   = {arxiv:2310.02596},
    year      = {2023},
    }</code></pre>
    </div>
    </div> -->

</body>
<footer>
    This project page is inspired by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies.</a>, © Hongbin Xu. All rights reserved.
</footer>

</html>
